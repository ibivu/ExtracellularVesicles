{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Random forest model training\n",
    "\n",
    "### Workflow\n",
    "- Preprocessing of data (train-test-split, class balancing, scaling) \n",
    "- Training random forest classifiers (all and seq)\n",
    "\n",
    "### Created datasets\n",
    "- EV_RF_model_no_filter.pkl (RF model)\n",
    "- EV_RF_model_MS_filter.pkl (RF model)\n",
    "- EV_RF_model_MS_iso_filter.pkl (RF model)\n",
    "- EV_scaler_MS_iso_filter.pkl (Scaler)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gzip\n",
    "import pandas as pd\n",
    "import pickle\n",
    "import os\n",
    "\n",
    "from imblearn.under_sampling import RandomUnderSampler\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import RobustScaler\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define paths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "Data_path = os.path.dirname(os.getcwd()) + '/Data'\n",
    "Model_path = os.path.dirname(os.getcwd()) + '/Models'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Feature datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_unfiltered = pd.read_csv(Data_path + '/training/training_data_no_filter.csv', sep=',')\n",
    "df_MS_filter = pd.read_csv(Data_path + '/training/training_data_MS_filter.csv', sep=',')\n",
    "df_MS_iso_filter = pd.read_csv(Data_path + '/training/training_data_MS_iso_filter.csv', sep=',')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create Random Forest models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "continuous = ['length', 'hydr_count', 'polar_count', 'molecular_weight', 'helix', 'turn', 'sheet', \n",
    "    'A', 'C', 'D', 'E', 'F', 'G', 'H', 'I', 'K', 'L', 'M', 'N', 'P', 'Q', 'R', 'S', 'T', 'V', 'W', 'Y', \n",
    "    'thsa_netsurfp2', 'tasa_netsurfp2', 'rhsa_netsurfp2', 'disorder', 'A_exposed', 'C_exposed', 'D_exposed', \n",
    "    'E_exposed', 'F_exposed', 'G_exposed', 'H_exposed', 'I_exposed', 'K_exposed', 'L_exposed', 'M_exposed', \n",
    "    'N_exposed', 'P_exposed', 'Q_exposed', 'R_exposed', 'S_exposed', 'T_exposed', 'V_exposed', 'W_exposed', \n",
    "    'Y_exposed', 'Probability_solubility', 'Aggregation_propensity', 'Aromaticity', 'Instability_index', \n",
    "    'Gravy', 'Isoelectric_point', 'Charge_at_7', 'Charge_at_5', 'Polar_exposed', 'Hydrophobic_exposed']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess(df):\n",
    "    \n",
    "    # define explanatory and response variables\n",
    "    X = df.drop([\"id\", \"EV\"], axis=1)\n",
    "    y = df[\"EV\"]\n",
    "    \n",
    "    # undersample majority class\n",
    "    undersample = RandomUnderSampler(random_state=0)\n",
    "    X_balanced, y_balanced = undersample.fit_resample(X, y)\n",
    "    \n",
    "    return X_balanced, y_balanced\n",
    "\n",
    "\n",
    "def split_and_scale(X_balanced, y_balanced, features_cont=continuous, scaler=RobustScaler()):\n",
    "\n",
    "    # split 80% training and 20% test \n",
    "    train_X, test_X, train_y, test_y = train_test_split(X_balanced, y_balanced, test_size=0.2, random_state=0, \n",
    "        stratify=y_balanced)\n",
    "    \n",
    "    # robust scaling\n",
    "    train_X_scaled = train_X.copy()\n",
    "    test_X_scaled = test_X.copy()\n",
    "    train_X_scaled[features_cont] = scaler.fit_transform(train_X[features_cont])\n",
    "    test_X_scaled[features_cont] = scaler.transform(test_X[features_cont])\n",
    "    \n",
    "    print(\"Size of training set:\", len(train_X_scaled))\n",
    "    print(\"Size of test set:\", len(test_X_scaled))\n",
    "    \n",
    "    return train_X_scaled, train_y, test_X_scaled, test_y, scaler"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Preprocess data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset with no filtering\n",
      "Size of training set: 13452\n",
      "Size of test set: 3364\n",
      "---------------------\n",
      "Dataset with MS filtering\n",
      "Size of training set: 8817\n",
      "Size of test set: 2205\n",
      "---------------------\n",
      "Dataset with MS and isolation method filtering\n",
      "Size of training set: 9544\n",
      "Size of test set: 2386\n"
     ]
    }
   ],
   "source": [
    "print(\"Dataset with no filtering\")\n",
    "X_balanced_1, y_balanced_1 = preprocess(df_unfiltered)\n",
    "train_X_1, train_y_1, test_X_1, test_y_1, scaler_1 = split_and_scale(X_balanced_1, y_balanced_1)\n",
    "print(\"---------------------\")\n",
    "print(\"Dataset with MS filtering\")\n",
    "X_balanced_2, y_balanced_2 = preprocess(df_MS_filter)\n",
    "train_X_2, train_y_2, test_X_2, test_y_2, scaler_2 = split_and_scale(X_balanced_2, y_balanced_2)\n",
    "print(\"---------------------\")\n",
    "print(\"Dataset with MS and isolation method filtering\")\n",
    "X_balanced_3, y_balanced_3 = preprocess(df_MS_iso_filter)\n",
    "train_X_3, train_y_3, test_X_3, test_y_3, scaler_3 = split_and_scale(X_balanced_3, y_balanced_3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train the random forest models (all features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomForestClassifier(max_features=10, n_estimators=1000, random_state=0)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rf_1 = RandomForestClassifier(random_state=0, n_estimators=1000, max_features=10)\n",
    "rf_1.fit(train_X_1, train_y_1)\n",
    "\n",
    "rf_2 = RandomForestClassifier(random_state=0, n_estimators=1000, max_features=10)\n",
    "rf_2.fit(train_X_2, train_y_2)\n",
    "\n",
    "rf_3 = RandomForestClassifier(random_state=0, n_estimators=1000, max_features=10)\n",
    "rf_3.fit(train_X_3, train_y_3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Save models (all features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "file = gzip.GzipFile(Model_path + '/EV_RF_model_no_filter.pkl', 'wb')\n",
    "file.write(pickle.dumps(rf_1))\n",
    "file.close()\n",
    "\n",
    "file = gzip.GzipFile(Model_path + '/EV_RF_model_MS_filter.pkl', 'wb')\n",
    "file.write(pickle.dumps(rf_2))\n",
    "file.close()\n",
    "\n",
    "file = gzip.GzipFile(Model_path + '/EV_RF_model_MS_iso_filter.pkl', 'wb')\n",
    "file.write(pickle.dumps(rf_3))\n",
    "file.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Save scaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(Model_path + '/EV_scaler_MS_iso_filter.pkl', 'wb') as file:\n",
    "    file.write(pickle.dumps(scaler_3))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train the random forest models (sequence-based features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# use only sequence-based features\n",
    "seq_features = ['length', 'hydr_count', 'polar_count', 'molecular_weight', 'helix', 'turn', 'sheet', 'A', 'C', 'D', 'E', 'F', \n",
    "                'G', 'H', 'I', 'K', 'L', 'M', 'N', 'P', 'Q', 'R', 'S', 'T', 'V', 'W', 'Y', 'thsa_netsurfp2', 'tasa_netsurfp2', \n",
    "                'rhsa_netsurfp2', 'disorder', 'A_exposed', 'C_exposed', 'D_exposed', 'E_exposed', 'F_exposed',\n",
    "                'G_exposed', 'H_exposed', 'I_exposed', 'K_exposed', 'L_exposed', 'M_exposed', 'N_exposed', 'P_exposed', \n",
    "                'Q_exposed', 'R_exposed', 'S_exposed', 'T_exposed', 'V_exposed', 'W_exposed', 'Y_exposed', \n",
    "                'Probability_solubility', 'Aggregation_propensity', 'Aromaticity', 'Instability_index', 'Gravy', \n",
    "                'Isoelectric_point', 'Charge_at_7', 'Charge_at_5', 'PTM_MSD', 'Phosphorylation_MSD',\n",
    "                'Glycosylation_MSD', 'Ubiquitination_MSD', 'SUMOylation_MSD', 'Acetylation_MSD', 'Palmitoylation_MSD', \n",
    "                'Methylation_MSD', 'coiled_coil', 'RAS_profile', 'ww_domain', 'EGF', 'RRM',\n",
    "                'TMHMM', 'Polar_exposed', 'Hydrophobic_exposed']\n",
    "\n",
    "train_X_1_seq = train_X_1[seq_features]\n",
    "test_X_1_seq = test_X_1[seq_features]\n",
    "\n",
    "train_X_2_seq = train_X_2[seq_features]\n",
    "test_X_2_seq = test_X_2[seq_features]\n",
    "\n",
    "train_X_3_seq = train_X_3[seq_features]\n",
    "test_X_3_seq = test_X_3[seq_features]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomForestClassifier(max_features=10, n_estimators=1000, random_state=0)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rf_1_seq = RandomForestClassifier(random_state=0, n_estimators=1000, max_features=10)\n",
    "rf_1_seq.fit(train_X_1_seq, train_y_1)\n",
    "\n",
    "rf_2_seq = RandomForestClassifier(random_state=0, n_estimators=1000, max_features=10)\n",
    "rf_2_seq.fit(train_X_2_seq, train_y_2)\n",
    "\n",
    "rf_3_seq = RandomForestClassifier(random_state=0, n_estimators=1000, max_features=10)\n",
    "rf_3_seq.fit(train_X_3_seq, train_y_3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Save models (sequence-based features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "file = gzip.GzipFile(Model_path + '/EV_RF_model_no_filter_seq.pkl', 'wb')\n",
    "file.write(pickle.dumps(rf_1_seq))\n",
    "file.close()\n",
    "\n",
    "file = gzip.GzipFile(Model_path + '/EV_RF_model_MS_filter_seq.pkl', 'wb')\n",
    "file.write(pickle.dumps(rf_2_seq))\n",
    "file.close()\n",
    "\n",
    "file = gzip.GzipFile(Model_path + '/EV_RF_model_MS_iso_filter_seq.pkl', 'wb')\n",
    "file.write(pickle.dumps(rf_3_seq))\n",
    "file.close()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
